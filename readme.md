# ğŸ§  Dual-Agent Debate Pattern (LangGraph + Groq)

This project implements a **Dual-Agent Debate Architecture** using **LangGraph** and **Groq LLMs**, where two AI agents (Pro and Con) debate a given question and a Moderator synthesizes a balanced final answer.

This pattern is useful for:

* Critical reasoning systems
* Decision support tools
* Ethical AI analysis
* Multi-perspective generation
* Advanced RAG/Agentic reasoning pipelines

---

## âœ¨ Key Idea

Instead of generating a single response, the system:

1. Creates a **Pro Agent** to support a position
2. Creates a **Con Agent** to challenge it
3. Uses a **Moderator Agent** to generate a final, balanced answer

This mimics **structured human debate**, improving reasoning depth and output quality.

---

## ğŸ—ï¸ Architecture

```mermaid
flowchart LR
    A[User Question] --> B(Pro Agent)
    B --> C(Con Agent)
    C --> D(Moderator Agent)
    D --> E[Final Balanced Answer]
```

---

## ğŸ”§ Tech Stack

* **LangGraph** â€“ for agent orchestration and state handling
* **LangChain** â€“ for prompt templates
* **Groq LLM** â€“ `llama-3.3-70b-versatile`
* **Python** â€“ core language
* **dotenv** â€“ environment variable handling

---

## âœ… Sample Input

```python
inputs = {"question": "Is AI safe for humanity?"}
```

## âœ… Sample Output (Excerpt)

> â€œThe question of whether AI is safe for humanity is complexâ€¦
> A balanced approach would involve acknowledging benefits while implementing strong safeguardsâ€¦â€

The final answer is **more nuanced and reliable** than a single-agent response.

---

## ğŸŒŸ Why this matters

Traditional LLM pipelines = one answer
This system = **multiple perspectives + critical thinking**

---


